{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_model import LSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from collections import deque\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import ASYNCHRONOUS\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RePAD2\n",
    "# ====================\n",
    "def calculate_aare(actual, predicted):\n",
    "\t\"\"\"\n",
    "\tCalculate the Absolute Relative Error (ARE) between an actual and predicted value.\n",
    "\t\n",
    "\tParameters:\n",
    "\tactual (deque): The actual value.\n",
    "\tpredicted (deque): The predicted value.\n",
    "\t\n",
    "\tReturns:\n",
    "\tfloat: The Absolute Relative Error.\n",
    "\t\"\"\"\n",
    "\t# Adding a small value epsilon to avoid division by zero\n",
    "\t#epsilon = 1e-10\n",
    "\taare_values = []\n",
    "\t\n",
    "\tfor act, pred in zip(actual, predicted):\n",
    "\t\tAARE = abs(act - pred) / max(abs(act), 1)\n",
    "\t\taare_values.append(AARE)\n",
    "\n",
    "\tmean_aare = np.mean(aare_values)\n",
    "\n",
    "\treturn mean_aare\n",
    "\n",
    "\n",
    "def calculate_threshold(aare_values):\n",
    "\t\"\"\"\n",
    "\tCalculate the threshold value (Thd) based on a deque of AARE values.\n",
    "\tThd is defined as the mean of the AARE values plus three times their standard deviation.\n",
    "\n",
    "\tParameters:\n",
    "\t- aare_values (array-like): An array of AARE values.\n",
    "\n",
    "\tReturns:\n",
    "\t- float: The calculated threshold value (Thd).\n",
    "\t\"\"\"\n",
    "\t# Calculate the mean and standard deviation of the AARE values\n",
    "\tmean_aare = np.mean(aare_values)\n",
    "\tstd_aare = np.std(aare_values)\n",
    "\t\n",
    "\t# Calculate Thd\n",
    "\tthd = mean_aare + 3 * std_aare\n",
    "\t\n",
    "\treturn thd\n",
    "\n",
    "# Function for creating and training model\n",
    "def train_model(train_events):\n",
    "\ttensor_y = torch.tensor(train_events, dtype=torch.float32).view(-1, 1, 1)\n",
    "\ttensor_x = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "\t# Create an instance of the LSTM model\n",
    "\tmodel = LSTM(tensor_x, tensor_y, input_size=1, hidden_size=10, num_layers=1, output_size=1, num_epochs=50, learning_rate=0.005)\n",
    "\t\n",
    "\tmodel.train_model() # Train the model\n",
    "\n",
    "\treturn model\n",
    "\n",
    "# Function for reporting anomalies to InfluxDB\n",
    "def report_anomaly(T, timestamp, actual_value, predicted_value, write_api):\n",
    "\t\"\"\"\n",
    "\tSends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "\twith both the same value and time as the original event.\n",
    "\n",
    "\tParameters:\n",
    "\t- anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "\t\"\"\"\n",
    "\n",
    "\tpoint = Point(\"base_detection-C53\")\\\n",
    "\t\t.tag(\"host\", \"detector\")\\\n",
    "\t\t.field(\"T\", float(T))\\\n",
    "\t\t.field(\"actual_value\", float(actual_value))\\\n",
    "\t\t.field(\"predicted_value\", float(predicted_value))\\\n",
    "\t\t.time(timestamp, WritePrecision.NS)\n",
    "\t\n",
    "\t#write_api.write(bucket=\"anomalies\", org=\"ORG\", record=point)\n",
    "\t#print(f\"Anomalous event sent to InfluxDB: Value={actual_value}, Time={timestamp}\")\n",
    "\n",
    "def write_result(timestamp, T, actual_value, predicted_value, AARE, Thd, write_api):\n",
    "\t\"\"\"\n",
    "\tSends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "\twith both the same value and time as the original event.\n",
    "\n",
    "\tParameters:\n",
    "\t- anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "\t\"\"\"\n",
    "\n",
    "\tpoint = Point(\"base_result-C53\")\\\n",
    "\t\t.tag(\"host\", \"detector\")\\\n",
    "\t\t.field(\"T\", float(T))\\\n",
    "\t\t.field(\"actual_value\", float(actual_value))\\\n",
    "\t\t.field(\"predicted_value\", float(predicted_value))\\\n",
    "\t\t.field(\"AARE\", float(AARE))\\\n",
    "\t\t.field(\"Thd\", float(Thd))\\\n",
    "\t\t.time(timestamp, WritePrecision.NS)\n",
    "\t\n",
    "\twrite_api.write(bucket=\"anomalies\", org=\"ORG\", record=point)\n",
    "\tprint(f'T: {T}, Real Value: {actual_value}, Prediction Value: {predicted_value}, AARE: {AARE}, Thd: {Thd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RoLA\n",
    "# ==================\n",
    "\n",
    "def to_rfc3339(timestamp_str):\n",
    "\t# This function converts a timestamp to RFC3339 format\n",
    "\tdt = datetime.fromisoformat(timestamp_str)  # Parse input timestamp\n",
    "\treturn dt.strftime('%Y-%m-%dT%H:%M:%SZ')\t# Convert to RFC3339 format\n",
    "\n",
    "def to_normal_time(timestamp_str):\n",
    "\t# This function converts a timestamp to %Y-%m-%d %H:%M format\n",
    "\tdt = datetime.fromisoformat(timestamp_str)  # Parse input timestamp\n",
    "\treturn dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def get_previous_values(bucket, measurement, timestamp, num_values, org, url, token, username, password):\n",
    "\t\"\"\"\n",
    "\tThis function queries the last \"num_values\" of a single \"measurement\" from and before the \"timestamp\" from \n",
    "\tInfluxDB multi-dimensional dataset in order to compute the correlation coefficient.\n",
    "\tIf values before the time stamp are less than \"num_values\" it gets all previous values.\n",
    "\n",
    "\tParameters:\n",
    "\t===========\n",
    "\t- bucket (str): \t\tInfluxDB bucket name.\n",
    "\t- measurement (str):\tThe variable name to extract.\n",
    "\t- timestamp (str): \t\tThe reference timestamp in RFC3339 format (e.g., \"2024-03-20T00:00:00Z\").\n",
    "\t- num_values (int): \tThe number of values (p) to extract.\n",
    "\t- org (str): \t\t\tInfluxDB organization name.\n",
    "\t- url (str): \t\t\tInfluxDB server URL.\n",
    "\t- token (str): \t\t\tAuthentication token.\n",
    "\t- username (str):\t\tAuthentication user name.\n",
    "\t- password (str):\t\tAuthentication password.\n",
    "\n",
    "\tReturns:\n",
    "\t- List of extracted values for the given variable from and before the timestamp.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tclient = InfluxDBClient(url=url, token=token, org=org, username=username, password=password)\n",
    "\tquery_api = client.query_api()\n",
    "\tformatted_timestamp = to_rfc3339(str(timestamp))\n",
    "\n",
    "\t# Construct the Flux query to extract one variable's values from a multi-dimensional dataset\n",
    "\tquery = f'''\n",
    "\tfrom(bucket: \"{bucket}\")\n",
    "\t  |> range(start:  time(v:\"2021-10-28T00:00:00Z\")) // the earliest timestamp\n",
    "\t  |> filter(fn: (r) => r[\"_field\"] == \"{measurement}\")\n",
    "\t  |> filter(fn: (r) => r[\"_time\"] <= time(v: \"{formatted_timestamp}\"))  // Before the timestamp\n",
    "\t  |> sort(columns: [\"_time\"], desc: true)\n",
    "\t  |> limit(n: {num_values})  // Extract up to num_values\n",
    "\t\t'''\n",
    "\n",
    "\t# Execute query\n",
    "\tresults = query_api.query(query=query, org=org)\n",
    "\n",
    "\t# Extract values\n",
    "\tvalues = [record.get_value() for table in results for record in table.records]\n",
    "\n",
    "\t#print(f\"Extracted values of '{measurement}' before {timestamp}:\")\n",
    "\treturn values\n",
    "\n",
    "\n",
    "def fetch_previous_values(var, timestamp, num_values):\n",
    "\t\"\"\"Fetches historical values for a given variable.\"\"\"\n",
    "\ttry:\n",
    "\t\treturn get_previous_values(\n",
    "\t\t\tbucket=bucket, measurement=var, timestamp=timestamp, num_values=num_values,\n",
    "\t\t\torg=org, url=influxdb_url, token=token, username=username, password=password\n",
    "\t\t)\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error fetching values for {var}: {e}\")\n",
    "\t\treturn []\n",
    "\n",
    "def fetch_events():\n",
    "\t\"\"\"\n",
    "\t This function fetches time-series events from InfluxDB.\n",
    "\t It is used in RoLA to extract the datapoint's relevant variable values from InFluxDB.\n",
    "\n",
    "\t Returns:\n",
    "\t ========\n",
    "\t List of available data points from InfluxDB stored multi-dimensional dataset.\n",
    "\t \"\"\"\n",
    "\tquery = f'''\n",
    "\t\tfrom(bucket: \"{bucket}\")\n",
    "\t\t|> range(start: time(v: \"{start_time}\"))\n",
    "\t\t|> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "\t\t|> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "\t'''\n",
    "\ttry:\n",
    "\t\treturn list(query_api.query_stream(org=org, query=query))\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error querying InfluxDB: {e}\")\n",
    "\t\treturn []\n",
    "\t  \n",
    "def is_anomaly(T, variable_name, state):\n",
    "\t\"\"\"\n",
    "\tThis function is an LDA-based anomaly detection function. It checks if a given data point (variable Vx at time T) is an anomaly. \n",
    "\tIt updates a given variable LDA's parameters dynamically.\n",
    "\tIn the multivariate case, each flux event consists of a time stamp and a combination of values (variables).\n",
    "\tThese values are treated as floats or other data types. Thus, get_value() is not used as in a single-value flux event. \n",
    "\t\n",
    "\tParameters:\n",
    "\t===========\n",
    "\t- T (int):\t\t\t\tThe time point of the current data point.\n",
    "\t- variable_name (str):\tThe name of the variable used for anomaly detection. \n",
    "\t- state (dict):\t\t\tA nested dictionary contains dictionaries (LDAs relevant arguments) associated with each variable. \n",
    "\t\t\t\t\t\t\tEach dictionary contains specific arguments for individual LDAs to store and update relevant variables data, such as:\n",
    "\t\n",
    "\t* batch_events (deque): A batch of **four time points** events D_T-3, D_T-2, D_T-1, and D_T, that are updated in each iteration.\n",
    "\t\t\t\t\t\t\tIt is used for predicting D_T+1 using batch_events[1:], and predicting D_T using batch_events[0:-1].\t\n",
    "\t* next_event (deque):\tThe event to predict next when T = 0, 1, 2, 3, 4, 5, and 6, which is updated in each iteration.\n",
    "\t* M (object):\t\t\tA trained LSTM model relevant to the current variable. The default value is \"None\". \n",
    "\t* flag (bool):\t\t\tA flag that indicates whether an anomaly was detected (falg=False) in the previous iteration. The default value is \"True\".\n",
    "\t* actual_value (deque):\tA sliding window of three elements to store the actual value of events within three iterations to calculate the AARE.\n",
    "\t* predicted_value (deque):\tA sliding window of three elements to store the predicted value of events within three iterations to calculate the AARE.\n",
    "\t* sliding_window_AARE (deque): A sliding window used for storing the AARE resulted in each iteration in order to calculate the threshold later.\n",
    "\t\n",
    "\tReturns:\t\n",
    "\t========\t\n",
    "\tAnomaly detection Bool value.\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Extract state variables\n",
    "\tvariable_state = state[variable_name]\n",
    "\tbatch_events = variable_state[\"batch_events\"]\n",
    "\tnext_event = variable_state[\"next_event\"]\n",
    "\tM = variable_state[\"M\"]\n",
    "\tflag = variable_state[\"flag\"]\n",
    "\tactual_value = variable_state[\"actual_value\"]\n",
    "\tpredicted_value = variable_state[\"predicted_value\"]\n",
    "\tsliding_window_AARE = variable_state[\"sliding_window_AARE\"]\n",
    "\n",
    "\tif T < 2:\n",
    "\t\treturn False\t# First events, no predictions. No anomaly detections.\n",
    "\n",
    "\t# Initialize LDA\n",
    "\tif 2 <= T < 5:\t# Make predictions of D_T+1 by training M with D_T-2, D_T-1, and D_T, i.e., (batch_events)[1:]. \n",
    "\t\tif T == 2:\t \n",
    "\t\t\tM = train_model(list(batch_events))\t   # batch_events contains only 3 values when T=2.\n",
    "\t\telse:\n",
    "\t\t\tM = train_model(list(batch_events)[1:])   # Ignore D_T-3 from the batch_events\n",
    "\t\t\n",
    "\t\tvariable_state[\"M\"] = M\n",
    "\t\tpred_D_T_plus_1 = M.predict_next()\n",
    "\n",
    "\t\tactual_value.append(next_event)\n",
    "\t\tpredicted_value.append(pred_D_T_plus_1)\n",
    "\n",
    "\t\treturn False   # Predictions without AAREs available. No anomaly detections.\n",
    "\n",
    "\telif 5 <= T < 7:   # Calculate AARE and append to sliding window.\n",
    "\t\tAARE_T = calculate_aare(actual_value, predicted_value)  # Calculate AARE \n",
    "\t\tsliding_window_AARE.append(AARE_T)\t\t\t\t\t  # Uppend to sliding window.\n",
    "\n",
    "\t\tM = train_model(list(batch_events)[1:])\t\t\t\t # Train M with (D_T-2, D_T-1, and D_T) to predict D_T+1.\n",
    "\t\tpred_D_T_plus_1 = M.predict_next()\n",
    "\n",
    "\t\tactual_value.append(next_event)\t\t\t\t\t\t # Append the event and its prediction to the sliding window.\n",
    "\t\tpredicted_value.append(pred_D_T_plus_1)\n",
    "\n",
    "\t\tvariable_state[\"M\"] = M\n",
    "\t\treturn False\t# Predictions without AARE thresholds available. No anomaly detections.\n",
    "\n",
    "\telif T >= 7:\t # Make predictions of D_T by training M (when is needed) with D_T-3, D_T-2, D_T-1, i.e., (batch_events)[0:-1]\n",
    "\t\tif flag:\t # True\n",
    "\t\t\tif T != 7:\t # Use previously trained model when T > 7, otherwise, calculate the AARE and the threshold and evaluate the AARE.\n",
    "\t\t\t\tpred_D_T = M.predict_next()\t\t   \n",
    "\t\t\t\tactual_value.append(batch_events[-1])\n",
    "\t\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\t\tsliding_window_AARE.append(AARE_T)\n",
    "\n",
    "\t\t\t# Calculate the threshold only once\n",
    "\t\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\t\t# train a new model if the AARE is larger than Thd, predict, and evaluate again\n",
    "\t\t\tif AARE_T > Thd:\n",
    "\t\t\t\tmodel = train_model(list(batch_events)[0:-1])\n",
    "\t\t\t\tpred_D_T = model.predict_next()\n",
    "\n",
    "\t\t\t\tactual_value.append(batch_events[-1])\n",
    "\t\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\t\t\tsliding_window_AARE.append(AARE_T)\n",
    "\n",
    "\t\t\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\t\t\tif AARE_T > Thd:\t # anomaly detected\n",
    "\t\t\t\t\tflag = False\n",
    "\t\t\t\telse:\t\t\t\t# AARE <= Thd. No anomaly. Replace the model\n",
    "\t\t\t\t\tvariable_state[\"M\"] = model\n",
    "\t\t\t\t\tflag = True\n",
    "\t\telse:   # if the flag is False, train a new model, predict and evaluate AARE\n",
    "\t\t\tmodel = train_model(list(batch_events)[0:-1])\n",
    "\t\t\tpred_D_T = model.predict_next()\n",
    "\t\t\tactual_value.append(batch_events[-1])\n",
    "\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\t\tsliding_window_AARE.append(AARE_T)\n",
    "\n",
    "\t\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\t\tif AARE_T > Thd:   # anomaly detected\n",
    "\t\t\t\tflag = False\n",
    "\t\t\telse:\t\t\t  # AARE <= Thd. No anomaly. Replace the model\n",
    "\t\t\t\tvariable_state[\"M\"] = model\n",
    "\t\t\t\tflag = True\n",
    "\n",
    "\t\treturn not flag\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean Processing Time: 0.0516 sec, Std Dev: 0.4120 sec \n",
      "\n",
      "\n",
      "2021-10-28 12:30\n",
      "2021-10-28 10:07\n",
      "2021-10-28 12:38\n",
      "2021-10-28 12:20\n",
      "2021-10-28 12:22\n",
      "2021-10-28 10:09\n",
      "2021-10-28 12:21\n",
      "2021-10-28 12:37\n",
      "2021-10-28 12:17\n",
      "2021-10-28 12:40\n",
      "2021-10-28 12:34\n",
      "2021-10-28 12:19\n",
      "2021-10-28 12:35\n",
      "2021-10-28 12:29\n",
      "2021-10-28 12:23\n",
      "2021-10-28 10:05\n",
      "2021-10-28 12:28\n",
      "2021-10-28 10:10\n",
      "2021-10-28 10:08\n",
      "2021-10-28 12:31\n",
      "2021-10-28 12:16\n",
      "2021-10-28 10:06\n",
      "2021-10-28 12:25\n",
      "2021-10-28 12:27\n",
      "2021-10-28 12:18\n",
      "2021-10-28 12:39\n",
      "2021-10-28 12:36\n",
      "2021-10-28 12:24\n",
      "2021-10-28 12:26\n",
      "2021-10-28 12:33\n",
      "2021-10-28 12:32\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 89\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(events) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     88\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo sufficient events found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m \ttime\u001b[38;5;241m.\u001b[39msleep(poll_interval)\n\u001b[0;32m     90\u001b[0m \t\u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     92\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### RoLA Algorithm ###\n",
    "'''\n",
    "Implementation:\n",
    "===============\n",
    "The algorithm is implemented according to the research RoLA paper (https://arxiv.org/pdf/2305.\n",
    " 16509). In short, the algorithm continuously streams time-series data from InfluxDB, detects anomalies\n",
    "for each variable at each time point T, and then, it applies polling based on correlation\n",
    "analysis to validate the detected anomalies. \n",
    "\n",
    "In the beginning, it connects to InfluxDB to stream data and defines parameters such as \n",
    "polling interval, correlation thresholds, and sliding window size, then it maintains \n",
    "a state dictionary for each variable to store relevant values, models, and flags.\n",
    "\n",
    "It uses a Flux query to fetch the latest time-series data from InfluxDB. Convert the streamed\n",
    "data into a list of events. Iterate Over Data Points in the Stream. For each time point T, extract\n",
    "an event (data point). For each variable in the event, it applies anomaly detection using the \n",
    "(is_anomaly function). Store detected anomalies in the list (anomalies) (which resets for each new time point). \n",
    "Correlation analysis and polling process are then initialized. If anomalies exist at T, compute \n",
    "Pearson’s correlation coefficient between each anomalous variable and all other variables. \n",
    "If a strongly correlated variable is also detected as an anomaly, increase the agreement counter. \n",
    "Otherwise, increase the disagreement counter. If the number of agreeing anomalies is greater than \n",
    "disagreeing ones, the detected anomalies are considered valid and the timestamp is outputted.\n",
    "\n",
    "To-Do:\n",
    "======\n",
    "Implementing parallel processing using PyTorch's parallelism features for running the is_anomaly \n",
    "function on all variables at time point T, by utilizing torch.multiprocessing. \n",
    "A modification is needed for the is_anomaly function including:\n",
    "\n",
    "- Using torch.multiprocessing to create a pool of worker processes.\n",
    "- create a function that prepares tasks for each variable and runs them in parallel using pool.starmap.\n",
    "- Collect the results (anomalies) and process them in the main loop.\n",
    "\n",
    "'''\n",
    "\n",
    "# Setting up the InfluxDB to consume data\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "username = \"influx-admin\"\n",
    "password = \"ThisIsNotThePasswordYouAreLookingFor\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "measurement = \"multivariate_dataset\"\n",
    "\n",
    "# Instantiate InfluxDB client\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org, username=username, password=password)\n",
    "write_api = client.write_api()\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Time series parameters\n",
    "T = 0\n",
    "p = 2880  # Number of previous values for correlation\n",
    "thd_pos, thd_neg = 0.95, -0.95\n",
    "poll_interval = 1  # Polling frequency in seconds\n",
    "time_increment = 1  # Time step increment\n",
    "start_time = \"2021-10-28T00:00:00Z\"\n",
    "\n",
    "# Variable names\n",
    "variables = [\n",
    "\t\"SEB45Salinity\", \"SEB45Conductivity\", \"OptodeConcentration\", \"OptodeSaturation\",\n",
    "\t\"C3Temperature\", \"FlowTemperature\", \"OptodeTemperature\", \"C3Turbidity\", \"FlowFlow\"\n",
    "]\n",
    "\n",
    "# State initialization for each variable\n",
    "state = {\n",
    "\tvar: {\n",
    "\t\t\"batch_events\": deque(maxlen=4),\n",
    "\t\t\"next_event\": deque(maxlen=1),\n",
    "\t\t\"actual_value\": deque([0] * 3, maxlen=3),\n",
    "\t\t\"predicted_value\": deque([0] * 3, maxlen=3),\n",
    "\t\t\"sliding_window_AARE\": deque(maxlen=8064),\n",
    "\t\t\"M\": None,\n",
    "\t\t\"flag\": True\n",
    "\t}\n",
    "\tfor var in variables\n",
    "}\n",
    "\n",
    "# List to store processing times\n",
    "processing_times = []\n",
    "anomaly_timestamps = []\n",
    "#anomaly_variable_sets = []\n",
    "#anomaly_datapoints_sets = []\n",
    "\n",
    "while True:\n",
    "\n",
    "\tevents = fetch_events()  # extract the available data points from a multi-dimensional dataset\n",
    "\tif len(events) < 3:\n",
    "\t\tprint(\"No sufficient events found.\")\n",
    "\t\ttime.sleep(poll_interval)\n",
    "\t\tcontinue\n",
    "\n",
    "\ttimestamp = 0\n",
    "\n",
    "\tfor i, event in enumerate(events):\t  # Iterate over each data point.\n",
    "\t\titeration_start_time = time.time()  # Start time of this iteration.\n",
    "\t\tanomalies = set()\t\t\t\t   # Reset anomalies for each data point. It is denoted by A in the paper\n",
    "\t\ttimestamp = event[\"_time\"]\t\t  # Extract timestamp.\n",
    "\n",
    "\t\t# Process each variable in the event\n",
    "\t\tfor var, value in event.values.items():\n",
    "\t\t\tif var in [\"result\", \"table\", \"_start\", \"_stop\", \"_time\", \"_measurement\", \"host\"]:\n",
    "\t\t\t\tcontinue\t\t\t\t\t# Exclude some metadata.\n",
    "\n",
    "\t\t\t# Continuously set batch events.\n",
    "\t\t\tstate[var][\"batch_events\"].append(value)\n",
    "\n",
    "\t\t\t# Set next event for early iterations (0 ≤ T < 7)\n",
    "\t\t\tif i < 7:\n",
    "\t\t\t\tstate[var][\"next_event\"] = events[i + 1][var]\n",
    "\n",
    "\t\t\t# Run anomaly detection for the current variable\n",
    "\t\t\tif is_anomaly(T, var, state):\n",
    "\t\t\t\tanomalies.add(var)\n",
    "\n",
    "\t\t# Correlation & Polling Process\n",
    "\t\tif anomalies:\t # Prepare a p-length window of previous values for each anomalous variable. Store them in a dictionary\n",
    "\t\t\tcorrelated_vars = {a: fetch_previous_values(a, timestamp, p) for a in anomalies}\n",
    "\n",
    "\t\t\tfor a in anomalies:  # \"anomalies\" is denoted by list A in the paper \n",
    "\t\t\t\tC_agree, C_disagree = 1, 0\n",
    "\t\t\t\tL_var, L_data = [a], [event[a]]\n",
    "\n",
    "\t\t\t\tfor b in variables:  # b is denoted by the y-th variable in the paper\n",
    "\t\t\t\t\tif b == a:\t   # Ignore b to mitigate redundant processing \n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\ta_values = correlated_vars.get(a, [])\t\t\t # Fetch the values associated with key \"a\" in correlated_vars dictionary\n",
    "\t\t\t\t\tb_values = fetch_previous_values(b, timestamp, p) # Fetch b previous values <= p \n",
    "\n",
    "\t\t\t\t\tif not a_values or not b_values:\t\t\t\t  # Try just when they are not empty\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tE_ab, _ = pearsonr(a_values, b_values)\n",
    "\t\t\t\t\texcept Exception:\n",
    "\t\t\t\t\t\tcontinue  # Computation errors\n",
    "\n",
    "\t\t\t\t\tif thd_neg <= E_ab <= thd_pos:\t\t\t\t\t # Continue if abs(E_ab) >= thd_pos  \n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tif b in anomalies:\t\t\t\t\t\t\t\t # Polling process\n",
    "\t\t\t\t\t\tC_agree += 1\n",
    "\t\t\t\t\t\tL_data.append(fetch_previous_values(b, timestamp, 1)) # include the variable value\n",
    "\t\t\t\t\t\tL_var.append(b)\t\t\t\t\t\t\t\t\t   # include the variable name\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tC_disagree += 1\n",
    "\n",
    "\t\t\t\tif C_agree > C_disagree and (C_agree + C_disagree) > 1:\n",
    "\t\t\t\t\tanomaly_timestamps.append(to_normal_time(str(timestamp)))  # Output results for testing\n",
    "\t\t\t\t\t#anomaly_variable_sets.append(L_var)\n",
    "\t\t\t\t\t#anomaly_datapoints_sets.append(L_data)\n",
    "\t\t\t\t\t#print(f\"====> T: {T} ===>  {timestamp}\\nVariables: {L_var}\\nData: {L_data}\")\n",
    "\n",
    "\t\t# Increment T for the next data point\n",
    "\t\tT += 1\n",
    "\t\titeration_end_time = time.time()\n",
    "\n",
    "\t\t# Compute and store processing time\n",
    "\n",
    "\t\tprocessing_time = iteration_end_time - iteration_start_time\n",
    "\t\tprocessing_times.append(processing_time)\n",
    "\n",
    "\t\t#print(f\"Processed timestamp: {timestamp}, Processing time: {processing_time:.4f} seconds\")\n",
    "\n",
    "\t# Compute mean and standard deviation every 10 iterations\n",
    "\t#if len(processing_times) % 10 == 0:\n",
    "\tmean_time = np.mean(processing_times)\n",
    "\tstd_time = np.std(processing_times)\n",
    "\tprint(f\"\\n\\nMean Processing Time of the Received Events: {mean_time:.4f} sec, Std Dev: {std_time:.4f} sec. \\n\\nTimestamp(s) in which anomalies are detected.\")\n",
    "\tfor tmstmp in set(anomaly_timestamps):\n",
    "\t\tprint(tmstmp)\n",
    "\t\t\n",
    "\t# Update start time for the next iteration\n",
    "\tstart_time = (timestamp + timedelta(seconds=time_increment)).isoformat()\n",
    "\n",
    "\ttime.sleep(poll_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
