{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_model import LSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from collections import deque\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import ASYNCHRONOUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RePAD2\n",
    "def calculate_aare(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate the Absolute Relative Error (ARE) between an actual and predicted value.\n",
    "    \n",
    "    Parameters:\n",
    "    actual (deque): The actual value.\n",
    "    predicted (deque): The predicted value.\n",
    "    \n",
    "    Returns:\n",
    "    float: The Absolute Relative Error.\n",
    "    \"\"\"\n",
    "    # Adding a small value epsilon to avoid division by zero\n",
    "    #epsilon = 1e-10\n",
    "    aare_values = []\n",
    "    \n",
    "    for act, pred in zip(actual, predicted):\n",
    "        AARE = abs(act - pred) / max(abs(act), 1)\n",
    "        aare_values.append(AARE)\n",
    "\n",
    "    mean_aare = np.mean(aare_values)\n",
    "\n",
    "    return mean_aare\n",
    "\n",
    "\n",
    "def calculate_threshold(aare_values):\n",
    "    \"\"\"\n",
    "    Calculate the threshold value (Thd) based on a deque of AARE values.\n",
    "    Thd is defined as the mean of the AARE values plus three times their standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - aare_values (array-like): An array of AARE values.\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated threshold value (Thd).\n",
    "    \"\"\"\n",
    "    # Calculate the mean and standard deviation of the AARE values\n",
    "    mean_aare = np.mean(aare_values)\n",
    "    std_aare = np.std(aare_values)\n",
    "    \n",
    "    # Calculate Thd\n",
    "    thd = mean_aare + 3 * std_aare\n",
    "    \n",
    "    return thd\n",
    "\n",
    "# Function for creating and training model\n",
    "def train_model(train_events):\n",
    "    tensor_y = torch.tensor(train_events, dtype=torch.float32).view(-1, 1, 1)\n",
    "    tensor_x = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "    # Create an instance of the LSTM model\n",
    "    model = LSTM(tensor_x, tensor_y, input_size=1, hidden_size=10, num_layers=1, output_size=1, num_epochs=50, learning_rate=0.005)\n",
    "    \n",
    "    model.train_model() # Train the model\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function for reporting anomalies to InfluxDB\n",
    "def report_anomaly(T, timestamp, actual_value, predicted_value, write_api):\n",
    "    \"\"\"\n",
    "    Sends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "    with both the same value and time as the original event.\n",
    "\n",
    "    Parameters:\n",
    "    - anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    point = Point(\"base_detection_multivariate_dataset\")\\\n",
    "        .tag(\"host\", \"detector\")\\\n",
    "        .field(\"T\", float(T))\\\n",
    "        .field(\"actual_value\", float(actual_value))\\\n",
    "        .field(\"predicted_value\", float(predicted_value))\\\n",
    "        .time(timestamp, WritePrecision.NS)\n",
    "    \n",
    "    #write_api.write(bucket=\"anomalies\", org=\"ORG\", record=point)\n",
    "    #print(f\"Anomalous event sent to InfluxDB: Value={actual_value}, Time={timestamp}\")\n",
    "\n",
    "def write_result(timestamp, T, actual_value, predicted_value, AARE, Thd, write_api):\n",
    "    \"\"\"\n",
    "    Sends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "    with both the same value and time as the original event.\n",
    "\n",
    "    Parameters:\n",
    "    - anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    point = Point(\"base_result_multivariate_dataset\")\\\n",
    "        .tag(\"host\", \"detector\")\\\n",
    "        .field(\"T\", float(T))\\\n",
    "        .field(\"actual_value\", float(actual_value))\\\n",
    "        .field(\"predicted_value\", float(predicted_value))\\\n",
    "        .field(\"AARE\", float(AARE))\\\n",
    "        .field(\"Thd\", float(Thd))\\\n",
    "        .time(timestamp, WritePrecision.NS)\n",
    "    \n",
    "    write_api.write(bucket=\"anomalies\", org=\"ORG\", record=point)\n",
    "    print(f'T: {T}, Real Value: {actual_value}, Prediction Value: {predicted_value}, AARE: {AARE}, Thd: {Thd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 0, Real Value: 34.324, Prediction Value: 0, AARE: 0, Thd: 0\n",
      "T: 1, Real Value: 34.324, Prediction Value: 0, AARE: 0, Thd: 0\n",
      "388 2021-10-28 06:28:00+00:00\n",
      "389 2021-10-28 06:29:00+00:00\n",
      "736 2021-10-28 12:16:00+00:00\n",
      "737 2021-10-28 12:17:00+00:00\n",
      "738 2021-10-28 12:18:00+00:00\n",
      "739 2021-10-28 12:19:00+00:00\n",
      "740 2021-10-28 12:20:00+00:00\n",
      "741 2021-10-28 12:21:00+00:00\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 251\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo events found in range.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 251\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(poll_interval)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### REPAD2 Algorithm ###\n",
    "\n",
    "\"\"\"\n",
    "Individual RePAD2 function for RoLA. The RoLA algorithm is not completely implemented.\n",
    "\n",
    "\"\"\"\n",
    "def individual_LDA(T, batch_events, next_event, M, flag, actual_value, predicted_value, sliding_window_AARE):\n",
    "\t# For printing the values\n",
    "\tAARE_T = 0\n",
    "\tThd = 0\n",
    "\n",
    "\t# Initialize the LDA\n",
    "\tif T >= 2 and T < 5:\n",
    "\t\t# Make predictions of D_T+1 by training M with D_T-2, D_T-1, and D_T, i.e., (batch_events)[1:]. \n",
    "\t\t\n",
    "\t\t# batch_events containes only 3 values when T=2.\n",
    "\t\tif T==2: \n",
    "\t\t\tM = train_model([event.get_value() for event in list(batch_events)])\n",
    "\t\t\n",
    "\t\t# Ignore D_T-3 from the batch_events\n",
    "\t\telse:\n",
    "\t\t\tM = train_model([event.get_value() for event in list(batch_events)[1:]])\t\t \n",
    "\t\t\n",
    "\t\tpred_D_T_plus_1 = M.predict_next()\n",
    "\t\t\n",
    "\t\t# Append the event and its prediction to the sliding window.\n",
    "\t\tactual_value.append(next_event.get_value())\n",
    "\t\tpredicted_value.append(pred_D_T_plus_1)\n",
    "\t\t\n",
    "\t\t# Write the results to InfluxDB.\n",
    "\t\t#write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-2], AARE_T, Thd, write_api) \n",
    "\t\t\n",
    "\t\treturn batch_events, next_event, M, actual_value, predicted_value, sliding_window_AARE, flag\n",
    "\n",
    "\telif T >= 5 and T < 7:\n",
    "\t\t# Calculate AARE and append to sliding window.\n",
    "\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\tsliding_window_AARE.append(AARE_T)\n",
    "\t\t\n",
    "\t\t# Train M with (D_T-2, D_T-1, and D_T) to predict D_T+1.\n",
    "\t\tM = train_model([event.get_value() for event in list(batch_events)[1:]])\n",
    "\t\tpred_D_T_plus_1 = M.predict_next()\n",
    "\t\t\n",
    "\t\t# Append the event and its prediction to the sliding window.\n",
    "\t\tactual_value.append(next_event.get_value())\n",
    "\t\tpredicted_value.append(pred_D_T_plus_1)\n",
    "\n",
    "\t\t# Write the results to InfluxDB.\n",
    "\t\t#write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-2], AARE_T, Thd, write_api) \n",
    "\n",
    "\t\treturn batch_events, next_event,  M, actual_value, predicted_value, sliding_window_AARE, flag\n",
    "\t\t\n",
    "\t# Make predictions of D_T by training M with D_T-3, D_T-2, D_T-1, i.e., (batch_events)[0:-1]\n",
    "\telif T >= 7 and flag == True:\t\t\t\t\t\t\t\n",
    "\t\tif T != 7:\n",
    "\t\t\t# Use M to precdict D_T.\n",
    "\t\t\tpred_D_T = M.predict_next()\n",
    "\t\t\t\n",
    "\t\t\t# Append the event (last event in batch_events) and its prediction to the sliding window.\n",
    "\t\t\tactual_value.append(batch_events[-1].get_value())\n",
    "\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t# Calculate AARE and append to sliding window\t\n",
    "\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\tsliding_window_AARE.append(AARE_T)\n",
    "\t\t\n",
    "\t\t# Calculate Thd\n",
    "\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\t\t\n",
    "\t\tif AARE_T <= Thd: pass \t\t# D_T is not reported as anomaly\n",
    "\t\telse:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t# Train an LSTM model with D_T-3, D_T-2, D_T-1: list(batch_events)[0:-1]\t\t  \n",
    "\t\t\tmodel = train_model([event.get_value() for event in list(batch_events)[0:-1]]) \n",
    "\t\t\t# Use the model to predict D_T\n",
    "\t\t\tpred_D_T = model.predict_next()\n",
    "\t\t\t\n",
    "\t\t\t# Append the event (last event in batch_events) and its prediction to the sliding window\n",
    "\t\t\tactual_value.append(batch_events[-1].get_value())\n",
    "\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t\t# Re-calculate AARE_T\n",
    "\t\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\t\tsliding_window_AARE.append(AARE_T)\n",
    "\t\t\t\n",
    "\t\t\t# Re-calculate Thd\n",
    "\t\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\t\tif AARE_T <= Thd:\n",
    "\t\t\t\t# D_T is not reported as anomaly\n",
    "\t\t\t\t# Replace M with the new model\n",
    "\t\t\t\tM = model\n",
    "\t\t\t\t# Update flag to True\n",
    "\t\t\t\tflag = True\n",
    "\t\t\telse:\n",
    "\t\t\t\t# D_T reported as anomaly immediately, and update flag to False\n",
    "\t\t\t\tflag = False\n",
    "\t\t\t\t#report_anomaly(T, batch_events[-1].get_time(), actual_value[-1], predicted_value[-1], write_api)\n",
    "\t\t\t\t\n",
    "\t\t# Write the results to InfluxDB\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t### delete later\n",
    "\t\t#write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-1], AARE_T, Thd, write_api) \t### delete later\n",
    "\t\treturn batch_events, next_event, M, actual_value, predicted_value, sliding_window_AARE, flag\n",
    "\t\t\t\n",
    "\n",
    "\telif T >= 7 and flag == False:\n",
    "\t\t# Train an LSTM model with D_T-3, D_T-2, D_T-1\n",
    "\t\tmodel = train_model([event.get_value() for event in list(batch_events)[0:-1]])\n",
    "\t\t# Use the model to predict D_T\n",
    "\t\tpred_D_T = model.predict_next()\n",
    "\t\t# Append the event and its prediction to the sliding window\n",
    "\t\tactual_value.append(batch_events[-1].get_value())\n",
    "\t\tpredicted_value.append(pred_D_T) \n",
    "\n",
    "\t\t# Calculate AARE_T\n",
    "\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\tsliding_window_AARE.append(AARE_T)\n",
    "\t\t# Calculate Thd\n",
    "\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\tif AARE_T <= Thd:\n",
    "\t\t\t# D_T is not reported as anomaly\n",
    "\t\t\t# Replace M with the new model\n",
    "\t\t\tM = model\n",
    "\t\t\t# Update flag to True\n",
    "\t\t\tflag = True\n",
    "\t\telse:\n",
    "\t\t\t# D_T reported as anomaly immediately, and update flag to False\n",
    "\t\t\tflag = False\n",
    "\t\t\t#report_anomaly(T, batch_events[-1].get_time(), actual_value[-1], predicted_value[-1], write_api)\n",
    "\t\t\n",
    "\t\t# Write the results to InfluxDB\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t### delete later\n",
    "\t\t#write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-1], AARE_T, Thd, write_api) \t### delete later\n",
    "\t\treturn batch_events, next_event, M, actual_value, predicted_value, sliding_window_AARE, flag\n",
    "\t\t\n",
    "\t\t\n",
    "# Setting up the InfluxDB to consume data\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "username = \"influx-admin\"\n",
    "password = \"ThisIsNotThePasswordYouAreLookingFor\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "measurement = \"multivariate_dataset\" \n",
    "\n",
    "# Instantiate the QueryAPI\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org, username=username, password=password)\n",
    "write_api = client.write_api(write_options=ASYNCHRONOUS)\n",
    "query_api = client.query_api()\n",
    "\n",
    "# RoLA specific\n",
    "T = 0\n",
    "\n",
    "# Data structures for training and predicting\n",
    "batch_events = deque(maxlen=4)\t\t\t\t\t# Events from time points: T-3, T-2, T-1, and T\n",
    "next_event = deque(maxlen=1)\t\t\t\t\t\t# Used in the case of predicting D_T+1\n",
    "\n",
    "# Sliding window for calculating the Threshold\n",
    "actual_value = deque([0] * 3, maxlen=3)\t\t\t# To append the actual event value in current iteration \n",
    "predicted_value = deque([0] * 3, maxlen=3)\t\t# To append the predicted event value in current iteration \n",
    "sliding_window_AARE = deque(maxlen=8064)\t\t\t# Tp append the resulting AARE in the current iteration\n",
    "\n",
    "M = 0\t\t\t\t\t\t\t\t\t\t\t# Trained LSTM model \n",
    "flag = True\t\t\t\t\t\t\t\t\t\t# True: no anomaly was ditected in the previous iteration\n",
    "\n",
    "# Time parameters\n",
    "poll_interval = 1  \t\t\t\t\t\t\t\t# Second(s)\n",
    "time_increment = 1 \t\t\t\t\t\t\t\t# Second(s)\n",
    "start_time = \"2021-10-28T00:00:00Z\" \t\t\t\t# The time of the first event in the time series data\n",
    "\t\n",
    "while True:\n",
    "\t\n",
    "\t# Construct the Flux query\n",
    "\t#query = f'''\n",
    "\t#from(bucket: \"{bucket}\")\n",
    "\t#\t|> range(start: time(v: \"{start_time}\"))\n",
    "\t#\t|> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "\t#'''\n",
    "\t# Query the data\n",
    "\t#events = list(query_api.query_stream(org=org, query=query))\n",
    "\n",
    "\t# Construct the Flux query to retrieve only one variable and timestamp\n",
    "\tquery = f'''\n",
    "\tfrom(bucket: \"{bucket}\")\n",
    "\t\t|> range(start: time(v: \"{start_time}\"))\n",
    "\t\t|> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "\t\t|> filter(fn: (r) => r[\"_field\"] == \"SEB45Salinity\")  \n",
    "\t\t|> keep(columns: [\"_time\", \"_value\"])  \n",
    "\t'''\n",
    "\t# Query the data\n",
    "\tevents = list(query_api.query_stream(org=org, query=query))   \n",
    "\n",
    "\t# Construct the Flux query for multiple variables\n",
    "\t#query = f'''\n",
    "\t#\t\tfrom(bucket: \"{bucket}\")\n",
    "\t#\t\t\t|> range(start: time(v: \"{start_time}\"))\n",
    "\t#\t\t\t|> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "\t#\t\t\t|> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "\t#\t\t'''\n",
    "\n",
    "\t# Query the data\n",
    "\t#events = list(query_api.query_stream(org=org, query=query))\n",
    "\n",
    "\n",
    "\tif len(events) > 1: \t\t\t\t\t\t# Need at least 3 to predict next and compare\n",
    "\n",
    "\t\tfor i in range(len(events)):\n",
    "\t\t\tbatch_events.append(events[i])\n",
    "\t\t\tif i < 7: \n",
    "\t\t\t\tnext_event = events[i+1]\t \t# used when  0 <= T < 7 to predict the next event. The 7th event is the last one predicted.\n",
    "\t\t\t\n",
    "\t\t\t# Print the default outputs when T=0 and T=1 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t### delete later\n",
    "\t\t\tif i in [0,1]: \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t### delete later\n",
    "\t\t\t\twrite_result(batch_events[-1].get_time(), i, batch_events[-1].get_value(), predicted_value[-1], 0, 0, write_api)\t### delete later\n",
    "\t\t\telse:\n",
    "\t\t\t\t# RePAD2 Algorithm\n",
    "\t\t\t\tbatch_events, next_event, M, actual_value, predicted_value, sliding_window_AARE, flag = individual_LDA(T, batch_events, next_event, M, flag, actual_value, predicted_value, sliding_window_AARE)\n",
    "\n",
    "\t\t\t\tif flag==False:\n",
    "\t\t\t\t\tprint(T, batch_events[-1].get_time())\n",
    "\t\t\t# Increment T\n",
    "\t\t\tT += 1\n",
    "\n",
    "\t\t# Update start time for the next iteration\n",
    "\t\tlast_event_time = batch_events[-1].get_time()\n",
    "\t\t# Increment by 1 second to avoid duplicate events\n",
    "\t\tstart_time = (last_event_time + timedelta(seconds=time_increment)).isoformat()\n",
    "\t\t\t\t\n",
    "\n",
    "\telse:\n",
    "\t\tprint(\"No events found in range.\")\n",
    "\n",
    "\ttime.sleep(poll_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
