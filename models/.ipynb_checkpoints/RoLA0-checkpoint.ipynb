{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_model import LSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from collections import deque\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import ASYNCHRONOUS\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RePAD2\n",
    "# ====================\n",
    "\n",
    "def calculate_aare(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate the Absolute Relative Error (ARE) between an actual and predicted value.\n",
    "    \n",
    "    Parameters:\n",
    "    actual (deque): The actual value.\n",
    "    predicted (deque): The predicted value.\n",
    "    \n",
    "    Returns:\n",
    "    float: The Absolute Relative Error.\n",
    "    \"\"\"\n",
    "    # Adding a small value epsilon to avoid division by zero\n",
    "    #epsilon = 1e-10\n",
    "    aare_values = []\n",
    "    \n",
    "    for act, pred in zip(actual, predicted):\n",
    "        AARE = abs(act - pred) / max(abs(act), 1)\n",
    "        aare_values.append(AARE)\n",
    "\n",
    "    mean_aare = np.mean(aare_values)\n",
    "\n",
    "    return mean_aare\n",
    "\n",
    "\n",
    "def calculate_threshold(aare_values):\n",
    "    \"\"\"\n",
    "    Calculate the threshold value (Thd) based on a deque of AARE values.\n",
    "    Thd is defined as the mean of the AARE values plus three times their standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - aare_values (array-like): An array of AARE values.\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated threshold value (Thd).\n",
    "    \"\"\"\n",
    "    # Calculate the mean and standard deviation of the AARE values\n",
    "    mean_aare = np.mean(aare_values)\n",
    "    std_aare = np.std(aare_values)\n",
    "    \n",
    "    # Calculate Thd\n",
    "    thd = mean_aare + 3 * std_aare\n",
    "    \n",
    "    return thd\n",
    "\n",
    "# Function for creating and training model\n",
    "def train_model(train_events):\n",
    "    tensor_y = torch.tensor(train_events, dtype=torch.float32).view(-1, 1, 1)\n",
    "    tensor_x = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "    # Create an instance of the LSTM model\n",
    "    model = LSTM(tensor_x, tensor_y, input_size=1, hidden_size=10, num_layers=1, output_size=1, num_epochs=50, learning_rate=0.005)\n",
    "    \n",
    "    model.train_model() # Train the model\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RoLA\n",
    "# ==================\n",
    "\n",
    "def to_rfc3339(timestamp_str):\n",
    "\t# This function converts a timestamp to RFC3339 format\n",
    "\tdt = datetime.fromisoformat(timestamp_str)  # Parse input timestamp\n",
    "\treturn dt.strftime('%Y-%m-%dT%H:%M:%SZ')\t# Convert to RFC3339 format\n",
    "\n",
    "\n",
    "\n",
    "def get_previous_values(bucket, measurement, timestamp, num_values, org, url, token, username, password):\n",
    "\t\"\"\"\n",
    "\tThis function queries the last \"num_values\" of a single \"measurement\" before \"timestamp\" from \n",
    "\tInfluxDB multi-dimensional dataset in order to compute the correlation coefficient.\n",
    "\tIf values before the time stamp are less than \"num_values\" it gets all previous values.\n",
    "\n",
    "\tParameters:\n",
    "\t===========\n",
    "\t- bucket (str): \t\tInfluxDB bucket name.\n",
    "\t- measurement (str):\tThe variable name to extract.\n",
    "\t- timestamp (str): \t\tThe reference timestamp in RFC3339 format (e.g., \"2024-03-20T00:00:00Z\").\n",
    "\t- num_values (int): \tThe number of values (p) to extract.\n",
    "\t- org (str): \t\t\tInfluxDB organization name.\n",
    "\t- url (str): \t\t\tInfluxDB server URL.\n",
    "\t- token (str): \t\t\tAuthentication token.\n",
    "\t- username (str):\t\tAuthentication user name.\n",
    "\t- password (str):\t\tAuthentication password.\n",
    "\n",
    "\tReturns:\n",
    "\t- List of extracted values for the given variable.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tclient = InfluxDBClient(url=url, token=token, org=org, username=username, password=password)\n",
    "\tquery_api = client.query_api()\n",
    "\tformatted_timestamp = to_rfc3339(str(timestamp))\n",
    "\n",
    "\t# Construct the Flux query to extract one variable's values from a multi-dimensional dataset\n",
    "\tquery = f'''\n",
    "\tfrom(bucket: \"{bucket}\")\n",
    "\t  |> range(start:  time(v:\"2021-10-28T00:00:00Z\")) // the earliest timestamp\n",
    "\t  |> filter(fn: (r) => r[\"_field\"] == \"{measurement}\")\n",
    "\t  |> filter(fn: (r) => r[\"_time\"] <= time(v: \"{formatted_timestamp}\"))  // Before the timestamp\n",
    "\t  |> sort(columns: [\"_time\"], desc: true)\n",
    "\t  |> limit(n: {num_values})  // Extract up to num_values\n",
    "\t\t'''\n",
    "\n",
    "\t# Execute query\n",
    "\tresults = query_api.query(query=query, org=org)\n",
    "\n",
    "\t# Extract values\n",
    "\tvalues = [record.get_value() for table in results for record in table.records]\n",
    "\n",
    "\t#print(f\"Extracted values of '{measurement}' before {timestamp}:\")\n",
    "\treturn values\n",
    "\t\n",
    "\n",
    "\n",
    "def is_anomaly(T, variable_name, state):\n",
    "\t\"\"\"\n",
    "\tThis function is an LDA-based anomaly detection function. It checks if a given data point (variable Vx at time T) is an anomaly. \n",
    "\tIt updates variable LDA's parameters dynamically.\n",
    "\tIn the multivariate case, each flux event consists of a time stamp and a combination of values.\n",
    "\tThese values are treated as floats or other data types. Thus, get_value() was not used as we did a flux event with one value. \n",
    "\t\n",
    "\tParameters:\n",
    "\t===========\n",
    "\t- T (int):\t\t\t\tThe given time point of the data point.\n",
    "\t- variable_name (str):\tThe name of the variable of the data point. \n",
    "\t- state (dict):\t\t\tA nested dictionary contains dictionaries associated with each variable. Each dictionary contains\n",
    "\t\t\t\t\t\t\tspecific arguments for an LDA to store and update relevant data, such as:\n",
    "\t\n",
    "\t* batch_events (deque): A batch of four time points events D_T-3, D_T-2, D_T-1, and D_T. It should be updated in each iteration.\n",
    "\t\t\t\t\t\t\tIt is used for predicting D_T+1 using batch_events[1:], and predicting D_T using batch_events[0:-1].\t\n",
    "\t* next_event (deque):\tThe event to predict next when T = 0, 1, 2, 3, 4, 5, and 6. It should be updated in each iteration.\n",
    "\t* M (object):\t\t\tA trained LSTM model. The default value is \"None\". \n",
    "\t* flag (bool):\t\t\tA flag that indicates whether an anomaly was detected (falg=False) in the previous iteration. The default value is \"True\".\n",
    "\t* actual_value (deque):\tA sliding window of three elements to store the actual value of events within three iterations to calculate the AARE.\n",
    "\t* predicted_value (deque):\tA sliding window of three elements to store the predicted value of events within three iterations to calculate the AARE.\n",
    "\t* sliding_window_AARE (deque): A sliding window used for storing the AARE resulted in each iteration in order to calculate the threshold later.\n",
    "\t\n",
    "\tReturn:\t\n",
    "\t=======\t\n",
    "\tThe flag indicating the anomaly, together with updated batch events, next events, actual_value, predicted_value, \n",
    "\tsliding_window_AARE, and the model that will be used in the next iteration.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\t# For printing the values\n",
    "\tAARE_T = 0\n",
    "\tThd = 0\n",
    "\tvariable_state   = state[variable_name]\n",
    "\t\n",
    "\tbatch_events\t= variable_state[\"batch_events\"]\n",
    "\tnext_event\t\t= variable_state[\"next_event\"]\n",
    "\tM\t\t\t\t   \t= variable_state[\"M\"]\n",
    "\tflag\t\t\t= variable_state[\"flag\"]\n",
    "\tactual_value\t= variable_state[\"actual_value\"]\n",
    "\tpredicted_value\t= variable_state[\"predicted_value\"]\n",
    "\tsliding_window_AARE = variable_state[\"sliding_window_AARE\"]\n",
    "\n",
    "\tif T < 2: \n",
    "\t\treturn False\n",
    "\t# Initialize the LDA\n",
    "\tif T >= 2 and T < 5:\n",
    "\t\t# Make predictions of D_T+1 by training M with D_T-2, D_T-1, and D_T, i.e., (batch_events)[1:]. \n",
    "\t\t\n",
    "\t\t# batch_events contains only 3 values when T=2.\n",
    "\t\tif T==2: \n",
    "\t\t\tM = train_model([event for event in list(batch_events)])\n",
    "\t\t\tvariable_state[\"M\"] = M\n",
    "\t\t\n",
    "\t\t# Ignore D_T-3 from the batch_events\n",
    "\t\telse:\n",
    "\t\t\tM = train_model([event for event in list(batch_events)[1:]])\n",
    "\t\t\tvariable_state[\"M\"] = M\n",
    "\t\t\n",
    "\t\tpred_D_T_plus_1 = M.predict_next()\n",
    "\t\t\n",
    "\t\t# Append the event and its prediction to the sliding window.\n",
    "\t\tactual_value.append(next_event)\n",
    "\t\tpredicted_value.append(pred_D_T_plus_1)\n",
    "\t\t\n",
    "\t\t# Write the results to InfluxDB.\n",
    "\t\t#write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-2], AARE_T, Thd, write_api) \n",
    "\t\t\n",
    "\t\t#return batch_events, next_event, M, actual_value, predicted_value, sliding_window_AARE, flag\n",
    "\t\treturn False\n",
    "\n",
    "\telif T >= 5 and T < 7:\n",
    "\t\t# Calculate AARE and append to sliding window.\n",
    "\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\tsliding_window_AARE.append(AARE_T)\n",
    "\t\t\n",
    "\t\t# Train M with (D_T-2, D_T-1, and D_T) to predict D_T+1.\n",
    "\t\tM = train_model([event for event in list(batch_events)[1:]])\n",
    "\t\tpred_D_T_plus_1 = M.predict_next()\n",
    "\t\t\n",
    "\t\t# Append the event and its prediction to the sliding window.\n",
    "\t\tactual_value.append(next_event)\n",
    "\t\tpredicted_value.append(pred_D_T_plus_1)\n",
    "\n",
    "\t\t# Update M for the next iteration. This has no effect with T=6 but is needed in the iteration when T>7\n",
    "\t\tvariable_state[\"M\"] = M\n",
    "\t\t\n",
    "\t\t# Write the results to InfluxDB.\n",
    "\t\t#write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-2], AARE_T, Thd, write_api) \n",
    "\n",
    "\t\t#return batch_events, next_event,  M, actual_value, predicted_value, sliding_window_AARE, flag\n",
    "\t\treturn False\n",
    "\t\t\n",
    "\t# Make predictions of D_T by training M with D_T-3, D_T-2, D_T-1, i.e., (batch_events)[0:-1]\n",
    "\telif T >= 7 and flag == True:\t\t\t\t\t\t\t\n",
    "\t\tif T != 7:\n",
    "\t\t\t# Use M to predict D_T.\n",
    "\t\t\tpred_D_T = M.predict_next()\n",
    "\t\t\t\n",
    "\t\t\t# Append the event (last event in batch_events) and its prediction to the sliding window.\n",
    "\t\t\tactual_value.append(batch_events[-1])\n",
    "\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t# Calculate AARE and append to sliding window\t\n",
    "\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\tsliding_window_AARE.append(AARE_T)\n",
    "\t\t\n",
    "\t\t# Calculate Thd\n",
    "\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\t\t\n",
    "\t\tif AARE_T <= Thd: pass \t\t# D_T is not reported as anomaly\n",
    "\t\telse:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t# Train an LSTM model with D_T-3, D_T-2, D_T-1: list(batch_events)[0:-1]\t\t  \n",
    "\t\t\tmodel = train_model([event for event in list(batch_events)[0:-1]]) \n",
    "\t\t\t# Use the model to predict D_T\n",
    "\t\t\tpred_D_T = model.predict_next()\n",
    "\t\t\t\n",
    "\t\t\t# Append the event (last event in batch_events) and its prediction to the sliding window\n",
    "\t\t\tactual_value.append(batch_events[-1])\n",
    "\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t\t# Re-calculate AARE_T\n",
    "\t\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\t\tsliding_window_AARE.append(AARE_T)\n",
    "\t\t\t\n",
    "\t\t\t# Re-calculate Thd\n",
    "\t\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\t\tif AARE_T <= Thd:\n",
    "\t\t\t\t# D_T is not reported as anomaly\n",
    "\t\t\t\t# Replace M with the new model\n",
    "\t\t\t\t#M = model\n",
    "\t\t\t\tvariable_state[\"M\"] = model\n",
    "\t\t\t\t# Update flag to True\n",
    "\t\t\t\tflag = True\n",
    "\t\t\telse:\n",
    "\t\t\t\t# D_T reported as anomaly immediately, and update flag to False\n",
    "\t\t\t\tflag = False\n",
    "\t\t\t\t#report_anomaly(T, batch_events[-1].get_time(), actual_value[-1], predicted_value[-1], write_api)\n",
    "\t\t\t\t\n",
    "\t\t# Write the results to InfluxDB\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t### delete later\n",
    "\t\t#write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-1], AARE_T, Thd, write_api) \t### delete later\n",
    "\t\t#return batch_events, next_event, M, actual_value, predicted_value, sliding_window_AARE, flag\n",
    "\t\treturn not flag\t\n",
    "\n",
    "\telif T >= 7 and flag == False:\n",
    "\t\t# Train an LSTM model with D_T-3, D_T-2, D_T-1\n",
    "\t\tmodel = train_model([event for event in list(batch_events)[0:-1]])\n",
    "\t\t# Use the model to predict D_T\n",
    "\t\tpred_D_T = model.predict_next()\n",
    "\t\t# Append the event and its prediction to the sliding window\n",
    "\t\tactual_value.append(batch_events[-1])\n",
    "\t\tpredicted_value.append(pred_D_T) \n",
    "\n",
    "\t\t# Calculate AARE_T\n",
    "\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\tsliding_window_AARE.append(AARE_T)\n",
    "\t\t# Calculate Thd\n",
    "\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\tif AARE_T <= Thd:\n",
    "\t\t\t# D_T is not reported as anomaly\n",
    "\t\t\t# Replace M with the new model\n",
    "\t\t\t#M = model\n",
    "\t\t\tvariable_state[\"M\"] = model\n",
    "\t\t\t# Update flag to True\n",
    "\t\t\tflag = True\n",
    "\t\telse:\n",
    "\t\t\t# D_T reported as anomaly immediately, and update flag to False\n",
    "\t\t\tflag = False\n",
    "\t\t\t#report_anomaly(T, batch_events[-1].get_time(), actual_value[-1], predicted_value[-1], write_api)\n",
    "\t\t\n",
    "\t\t# Write the results to InfluxDB\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t### delete later\n",
    "\t\t#write_result(batch_events[-1].get_time(), T, batch_events[-1].get_value(), predicted_value[-1], AARE_T, Thd, write_api) \t### delete later\n",
    "\t\t#return batch_events, next_event, M, actual_value, predicted_value, sliding_window_AARE, flag\n",
    "\t\treturn not flag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========> 2021-10-28T10:05:00Z \n",
      " ['OptodeConcentration', 'OptodeSaturation'] \n",
      " [215.5099945, [93.55999756]]\n",
      "==========> 2021-10-28T10:05:00Z \n",
      " ['OptodeSaturation', 'OptodeConcentration'] \n",
      " [92.26999664, [219.3399963]]\n",
      "==========> 2021-10-28T10:06:00Z \n",
      " ['OptodeConcentration', 'OptodeSaturation'] \n",
      " [236.6699982, [92.26999664]]\n",
      "==========> 2021-10-28T10:06:00Z \n",
      " ['OptodeSaturation', 'OptodeConcentration'] \n",
      " [100.5199966, [215.5099945]]\n",
      "==========> 2021-10-28T10:07:00Z \n",
      " ['OptodeConcentration', 'OptodeSaturation'] \n",
      " [239.7100067, [100.5199966]]\n",
      "==========> 2021-10-28T10:07:00Z \n",
      " ['OptodeSaturation', 'OptodeConcentration'] \n",
      " [101.8600006, [236.6699982]]\n",
      "==========> 2021-10-28T10:08:00Z \n",
      " ['OptodeConcentration', 'OptodeSaturation'] \n",
      " [232.7100067, [101.8600006]]\n",
      "==========> 2021-10-28T10:08:00Z \n",
      " ['OptodeSaturation', 'OptodeConcentration'] \n",
      " [98.88999939, [239.7100067]]\n",
      "==========> 2021-10-28T10:09:00Z \n",
      " ['OptodeConcentration', 'OptodeSaturation'] \n",
      " [229.9900055, [98.88999939]]\n",
      "==========> 2021-10-28T10:09:00Z \n",
      " ['OptodeSaturation', 'OptodeConcentration'] \n",
      " [97.73999786, [232.7100067]]\n",
      "==========> 2021-10-28T10:10:00Z \n",
      " ['OptodeConcentration', 'OptodeSaturation'] \n",
      " [229.4799957, [97.73999786]]\n",
      "==========> 2021-10-28T10:10:00Z \n",
      " ['OptodeSaturation', 'OptodeConcentration'] \n",
      " [97.51999664, [229.9900055]]\n",
      "==========> 2021-10-28T12:17:00Z \n",
      " ['OptodeConcentration', 'OptodeSaturation'] \n",
      " [208.5599976, [90.19000244]]\n",
      "==========> 2021-10-28T12:17:00Z \n",
      " ['OptodeSaturation', 'OptodeConcentration'] \n",
      " [89.23999786, [211.8300018]]\n",
      "==========> 2021-10-28T12:17:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [3.128999949, [19.154]]\n",
      "==========> 2021-10-28T12:17:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [17.537, [3.38499999]]\n",
      "==========> 2021-10-28T12:18:00Z \n",
      " ['C3Temperature', 'OptodeTemperature'] \n",
      " [30.03000069, [30.54999924]]\n",
      "==========> 2021-10-28T12:18:00Z \n",
      " ['OptodeTemperature', 'C3Temperature'] \n",
      " [30.79000092, [29.94000053]]\n",
      "==========> 2021-10-28T12:18:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.2409999967, [17.537]]\n",
      "==========> 2021-10-28T12:18:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [1.109, [3.128999949]]\n",
      "==========> 2021-10-28T12:19:00Z \n",
      " ['C3Temperature', 'OptodeTemperature'] \n",
      " [30.11000061, [30.79000092]]\n",
      "==========> 2021-10-28T12:19:00Z \n",
      " ['OptodeTemperature', 'C3Temperature'] \n",
      " [31.15999985, [30.03000069]]\n",
      "==========> 2021-10-28T12:19:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.2099999934, [1.109]]\n",
      "==========> 2021-10-28T12:19:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.961, [0.2409999967]]\n",
      "==========> 2021-10-28T12:20:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.199000001, [0.961]]\n",
      "==========> 2021-10-28T12:20:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.905, [0.2099999934]]\n",
      "==========> 2021-10-28T12:21:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.1879999936, [0.905]]\n",
      "==========> 2021-10-28T12:21:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.851, [0.199000001]]\n",
      "==========> 2021-10-28T12:22:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.1800000072, [0.851]]\n",
      "==========> 2021-10-28T12:22:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.814, [0.1879999936]]\n",
      "==========> 2021-10-28T12:23:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.175999999, [0.814]]\n",
      "==========> 2021-10-28T12:23:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.792, [0.1800000072]]\n",
      "==========> 2021-10-28T12:24:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.1710000038, [0.792]]\n",
      "==========> 2021-10-28T12:24:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.766, [0.175999999]]\n",
      "==========> 2021-10-28T12:25:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.1669999957, [0.766]]\n",
      "==========> 2021-10-28T12:25:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.745, [0.1710000038]]\n",
      "==========> 2021-10-28T12:26:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.1640000045, [0.745]]\n",
      "==========> 2021-10-28T12:26:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.731, [0.1669999957]]\n",
      "==========> 2021-10-28T12:27:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [35.20000076, [32.75999832]]\n",
      "==========> 2021-10-28T12:27:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [32.93000031, [35.59999847]]\n",
      "==========> 2021-10-28T12:27:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.1609999985, [0.731]]\n",
      "==========> 2021-10-28T12:27:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.713, [0.1640000045]]\n",
      "==========> 2021-10-28T12:28:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [35.70000076, [32.93000031]]\n",
      "==========> 2021-10-28T12:28:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.09000015, [35.20000076]]\n",
      "==========> 2021-10-28T12:28:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.1560000032, [0.713]]\n",
      "==========> 2021-10-28T12:28:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.69, [0.1609999985]]\n",
      "==========> 2021-10-28T12:29:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [35.59999847, [33.09000015]]\n",
      "==========> 2021-10-28T12:29:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.24000168, [35.70000076]]\n",
      "==========> 2021-10-28T12:29:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.1539999992, [0.69]]\n",
      "==========> 2021-10-28T12:29:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.679, [0.1560000032]]\n",
      "==========> 2021-10-28T12:30:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [36.09999847, [33.24000168]]\n",
      "==========> 2021-10-28T12:30:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.36000061, [35.59999847]]\n",
      "==========> 2021-10-28T12:30:00Z \n",
      " ['SEB45Conductivity', 'SEB45Salinity'] \n",
      " [0.150000006, [0.679]]\n",
      "==========> 2021-10-28T12:30:00Z \n",
      " ['SEB45Salinity', 'SEB45Conductivity'] \n",
      " [0.659, [0.1539999992]]\n",
      "==========> 2021-10-28T12:31:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [36.40000153, [33.36000061]]\n",
      "==========> 2021-10-28T12:31:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.52000046, [36.09999847]]\n",
      "==========> 2021-10-28T12:32:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [36.70000076, [33.52000046]]\n",
      "==========> 2021-10-28T12:32:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.54000092, [36.40000153]]\n",
      "==========> 2021-10-28T12:33:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [36.70000076, [33.54000092]]\n",
      "==========> 2021-10-28T12:33:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.52000046, [36.70000076]]\n",
      "==========> 2021-10-28T12:34:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [36.59999847, [33.52000046]]\n",
      "==========> 2021-10-28T12:34:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.43000031, [36.70000076]]\n",
      "==========> 2021-10-28T12:35:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [36.90000153, [33.43000031]]\n",
      "==========> 2021-10-28T12:35:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [34.22999954, [36.59999847]]\n",
      "==========> 2021-10-28T12:36:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [37.20000076, [34.22999954]]\n",
      "==========> 2021-10-28T12:36:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.97999954, [36.90000153]]\n",
      "==========> 2021-10-28T12:37:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [37.40000153, [33.97999954]]\n",
      "==========> 2021-10-28T12:37:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.93000031, [37.20000076]]\n",
      "==========> 2021-10-28T12:38:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [37.29999924, [33.93000031]]\n",
      "==========> 2021-10-28T12:38:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [33.88000107, [37.40000153]]\n",
      "==========> 2021-10-28T12:39:00Z \n",
      " ['C3Temperature', 'OptodeTemperature'] \n",
      " [33.09999847, [33.88000107]]\n",
      "==========> 2021-10-28T12:39:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [33.70000076, [33.88000107]]\n",
      "==========> 2021-10-28T12:39:00Z \n",
      " ['OptodeTemperature', 'C3Temperature', 'FlowTemperature'] \n",
      " [33.54999924, [32.88999939], [37.29999924]]\n",
      "==========> 2021-10-28T12:40:00Z \n",
      " ['FlowTemperature', 'OptodeTemperature'] \n",
      " [32.0, [33.54999924]]\n",
      "==========> 2021-10-28T12:40:00Z \n",
      " ['OptodeTemperature', 'FlowTemperature'] \n",
      " [31.03000069, [33.70000076]]\n",
      "timestamp 2021-10-30 23:59:00+00:00\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n",
      "No events found in range.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 127\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo events found in range.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 127\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(poll_interval)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### RoLA Algorithm ###\n",
    "'''\n",
    "This is the first RoLA implementation version coded exactly as found in the pseudo-code in the paper.\n",
    "However, for more efficient processing and readability, the code is optimized in another version called RoLA_model.ipynb. \n",
    "'''\n",
    "# Setting up the InfluxDB to consume data\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "username = \"influx-admin\"\n",
    "password = \"ThisIsNotThePasswordYouAreLookingFor\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "measurement = \"multivariate_dataset\" \n",
    "\n",
    "# Instantiate the QueryAPI\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org, username=username, password=password)\n",
    "write_api = client.write_api(write_options=ASYNCHRONOUS)\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Sttings\n",
    "T = 0\t\t\t\t\t\t\t\t\t\t\t# Time point\n",
    "A, L_var, L_data       = [], [], []\t\t\t\t\t# Lists for storing polling results\n",
    "C_agree, C_disagree = 0, 0\t\t\t\t\t\t# Counters\n",
    "p                               = 2880\t\t\t\t\t\t# The interval between two time points used in computing the correlation between two variables\n",
    "thd_pos, thd_neg      = 0.95, -0.95\t\t\t\t\t# The positive and negative Pearson's correlation coefficient thresholds\n",
    "poll_interval = 1  \t\t\t\t\t\t\t\t# Time parameter: Second(s)\n",
    "time_increment = 1 \t\t\t\t\t\t\t\t# Time parameter: Second(s)\n",
    "start_time = \"2021-10-28T00:00:00Z\" \t\t\t\t# The timestamp of the first event to start with in the given time series dataset\n",
    "\n",
    "\n",
    "# Initialize a state dictionary for each variable where each LDA stores and updates its arguments, such as \n",
    "# the batch events, trained model, the flag, and others.\n",
    "variables = [\"SEB45Salinity\", \"SEB45Conductivity\", \"OptodeConcentration\", \"OptodeSaturation\", \n",
    "\t\t\t\"C3Temperature\", \"FlowTemperature\", \"OptodeTemperature\", \"C3Turbidity\", \"FlowFlow\"]\n",
    "state        = { \n",
    "\t\t\tkey:{\"batch_events\": \tdeque(maxlen=4), \n",
    "\t\t\t\t \"next_event\": \t\tdeque(maxlen=1), \n",
    "\t\t\t\t \"actual_value\": \tdeque([0] * 3, maxlen=3), \n",
    "\t\t\t\t \"predicted_value\": \tdeque([0] * 3, maxlen=3), \n",
    "\t\t\t\t \"sliding_window_AARE\": deque(maxlen=8064), \n",
    "\t\t\t\t \"M\": \t\t\t\tNone, \n",
    "\t\t\t\t \"flag\": \t\t\tTrue \n",
    "\t\t\t\t }\n",
    "\t\t\tfor key in variables \n",
    "\t\t\t}\n",
    "\t\n",
    "while True:\n",
    "\t# Construct the Flux query to extract the available data points from a multi-dimensional dataset\n",
    "\tquery = f'''\n",
    "\t\t\tfrom(bucket: \"{bucket}\")\n",
    "\t\t\t\t|> range(start: time(v: \"{start_time}\"))\n",
    "\t\t\t\t|> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "\t\t\t\t|> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "\t\t\t'''\n",
    "\n",
    "\t# Query the data\n",
    "\tevents = list(query_api.query_stream(org=org, query=query))\n",
    "\n",
    "\t\n",
    "\tif len(events) > 1: \t\t\t\t\t\t# Need at least 3 events to predict next.\n",
    "\t\ttimestamp = 0\t\t\t\t\t\t# The timestamp of the last processed event.\n",
    "\t\tfor i in range(len(events)):\t\t\t# Iterate over each data point.\n",
    "\t\t\tevent = events[i]\t\t\t\t# The data point expressed by N-dimensional vector at time point T received by Flux query of readings sent by Kafka1.\n",
    "\t\t\ttimestamp = event[\"_time\"]  \t\t# Extract timestamp.\n",
    "\t\t\t\t\n",
    "\t\t\t# Iterate over each variable. Distribute variables to LDAs\n",
    "\t\t\tfor variable, value in event.values.items():\n",
    "\t\t\t\tif variable in [\"result\", \"table\",\"_start\",\"_stop\",\"_time\",\"_measurement\",\"host\"]: continue\n",
    "\n",
    "\t\t\t\t# Send the value (at time T) to the LDA's \"bach_events\" argument stored in the state dictionary.\n",
    "\t\t\t\tstate[variable][\"batch_events\"].append(value)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Send the next value (at time T+1) to the LDA's \"next_event\" argument stored in the state dictionary. \n",
    "\t\t\t\t# This is used for the LDA to predict the next event when  0 <= T < 7. The 7th event is the last one predicted.\n",
    "\t\t\t\tif i < 7: \n",
    "\t\t\t\t\tstate[variable][\"next_event\"] = events[i+1][variable]\t \t\n",
    "\n",
    "\t\t\t\t# Run anomaly detection of the current variable at time T with updated state.\n",
    "\t\t\t\tanomaly = is_anomaly(T, variable, state)\n",
    "\t\t\t\tif anomaly:\n",
    "\t\t\t\t\tA.append(variable)\n",
    "\n",
    "\t\t\t# Calculate the Pearson's correlation coefficients between the anomalous variables and proceed with polling\n",
    "\t\t\tif len(A) > 0:\n",
    "\t\t\t\tfor y in range(0,len(A)):\n",
    "\t\t\t\t\tC_agree      \t= 1\n",
    "\t\t\t\t\tC_disagree \t= 0\n",
    "\t\t\t\t\tL_var   \t\t= []\n",
    "\t\t\t\t\tL_data \t\t= []\n",
    "\t\t\t\t\ta = A[y]\t\t\t\n",
    "\t\t\t\t\tL_var.append(a)\n",
    "\t\t\t\t\tSa_T = event[a]\n",
    "\t\t\t\t\tL_data.append(Sa_T)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Correlations process\n",
    "\t\t\t\t\tfor z in range(len(variables)):\n",
    "\t\t\t\t\t\tif variables[z] != a:\n",
    "\t\t\t\t\t\t\tb = variables[z]\n",
    "\t\t\t\t\t\t\ta_values = get_previous_values(bucket=bucket, measurement=a, timestamp=timestamp, num_values=p, org=org, url=influxdb_url, token=token,username=username, password=password)\n",
    "\t\t\t\t\t\t\tb_values = get_previous_values(bucket=bucket, measurement=b, timestamp=timestamp, num_values=p, org=org, url=influxdb_url, token=token,username=username, password=password)\n",
    "\t\t\t\t\t\t\tE_ab, _ =  pearsonr(a_values, b_values)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# Polling process\n",
    "\t\t\t\t\t\t\tif (E_ab >= thd_pos) or (E_ab <= thd_neg):\n",
    "\t\t\t\t\t\t\t\tif b in A:\n",
    "\t\t\t\t\t\t\t\t\tC_agree += 1\n",
    "\t\t\t\t\t\t\t\t\tL_data.append(get_previous_values(bucket=bucket, measurement=b, timestamp=timestamp, num_values=1, org=org, url=influxdb_url, token=token,username=username, password=password))\n",
    "\t\t\t\t\t\t\t\t\tL_var.append(b)\n",
    "\t\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t\tC_disagree += 1\n",
    "\t\t\t\t\tif (C_agree > C_disagree) and ( (C_agree + C_disagree) > 1): print('==========>',to_rfc3339(str(timestamp)),'\\n',L_var,'\\n',L_data)\n",
    "\t\t\t\t\t#\t#for T_data, T_var in zip(L_data, L_var):\n",
    "\t\t\t\t\t#\t\t#print(timestamp, T_data, T_var)\n",
    "\t\t\t# Reset A\n",
    "\t\t\tA = []\n",
    "\t\t\t# Increment T\n",
    "\t\t\tT += 1  \n",
    "\n",
    "\t\tprint('timestamp', timestamp)\n",
    "\t\t# Update start time for the next iteration\n",
    "\t\tlast_event_time = timestamp\n",
    "\t\t#last_event_time = batch_events[-1].get_time()\n",
    "\t\t# Increment by 1 second to avoid duplicate events\n",
    "\t\tstart_time = (last_event_time + timedelta(seconds=time_increment)).isoformat()\n",
    "\t\t\t\t\n",
    "\n",
    "\telse:\n",
    "\t\tprint(\"No events found in range.\")\n",
    "\n",
    "\ttime.sleep(poll_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
