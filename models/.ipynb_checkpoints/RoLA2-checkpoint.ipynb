{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_model import LSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from collections import deque\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import ASYNCHRONOUS\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for reproducibility\n",
    "torch.manual_seed(140)\n",
    "np.random.seed(140)\n",
    "random.seed(140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RePAD2\n",
    "def calculate_aare(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate the Absolute Relative Error (ARE) between an actual and predicted value.\n",
    "    \n",
    "    Parameters:\n",
    "    actual (deque): The actual value.\n",
    "    predicted (deque): The predicted value.\n",
    "    \n",
    "    Returns:\n",
    "    float: The Absolute Relative Error.\n",
    "    \"\"\"\n",
    "    # Adding a small value epsilon to avoid division by zero\n",
    "    #epsilon = 1e-10\n",
    "    aare_values = []\n",
    "    \n",
    "    for act, pred in zip(actual, predicted):\n",
    "        AARE = abs(act - pred) / max(abs(act), 1)\n",
    "        aare_values.append(AARE)\n",
    "\n",
    "    mean_aare = np.mean(aare_values)\n",
    "\n",
    "    return mean_aare\n",
    "\n",
    "\n",
    "def calculate_threshold(aare_values):\n",
    "    \"\"\"\n",
    "    Calculate the threshold value (Thd) based on a deque of AARE values.\n",
    "    Thd is defined as the mean of the AARE values plus three times their standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "    - aare_values (array-like): An array of AARE values.\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated threshold value (Thd).\n",
    "    \"\"\"\n",
    "    # Calculate the mean and standard deviation of the AARE values\n",
    "    mean_aare = np.mean(aare_values)\n",
    "    std_aare = np.std(aare_values)\n",
    "    \n",
    "    # Calculate Thd\n",
    "    thd = mean_aare + 3 * std_aare\n",
    "    \n",
    "    return thd\n",
    "\n",
    "# Function for creating and training model\n",
    "def train_model(train_events):\n",
    "    tensor_y = torch.tensor(train_events, dtype=torch.float32).view(-1, 1, 1)\n",
    "    tensor_x = torch.tensor([1, 2, 3], dtype=torch.float32).view(-1, 1, 1)\n",
    "    # Create an instance of the LSTM model\n",
    "    model = LSTM(tensor_x, tensor_y, input_size=1, hidden_size=10, num_layers=1, output_size=1, num_epochs=50, learning_rate=0.005)\n",
    "    \n",
    "    model.train_model() # Train the model\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function for reporting anomalies to InfluxDB\n",
    "def report_anomaly(T, timestamp, actual_value, predicted_value, write_api):\n",
    "    \"\"\"\n",
    "    Sends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "    with both the same value and time as the original event.\n",
    "\n",
    "    Parameters:\n",
    "    - anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    point = Point(\"base_detection-C53\")\\\n",
    "        .tag(\"host\", \"detector\")\\\n",
    "        .field(\"T\", float(T))\\\n",
    "        .field(\"actual_value\", float(actual_value))\\\n",
    "        .field(\"predicted_value\", float(predicted_value))\\\n",
    "        .time(timestamp, WritePrecision.NS)\n",
    "    \n",
    "    #write_api.write(bucket=\"anomalies\", org=\"ORG\", record=point)\n",
    "    #print(f\"Anomalous event sent to InfluxDB: Value={actual_value}, Time={timestamp}\")\n",
    "\n",
    "def write_result(timestamp, T, actual_value, predicted_value, AARE, Thd, write_api):\n",
    "    \"\"\"\n",
    "    Sends an anomalous event back to InfluxDB, storing it in the \"anomaly\" measurement\n",
    "    with both the same value and time as the original event.\n",
    "\n",
    "    Parameters:\n",
    "    - anomalous_event: The event data that was detected as an anomaly, including its value and timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    point = Point(\"base_result-C53\")\\\n",
    "        .tag(\"host\", \"detector\")\\\n",
    "        .field(\"T\", float(T))\\\n",
    "        .field(\"actual_value\", float(actual_value))\\\n",
    "        .field(\"predicted_value\", float(predicted_value))\\\n",
    "        .field(\"AARE\", float(AARE))\\\n",
    "        .field(\"Thd\", float(Thd))\\\n",
    "        .time(timestamp, WritePrecision.NS)\n",
    "    \n",
    "    write_api.write(bucket=\"anomalies\", org=\"ORG\", record=point)\n",
    "    print(f'T: {T}, Real Value: {actual_value}, Prediction Value: {predicted_value}, AARE: {AARE}, Thd: {Thd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for RoLA\n",
    "# ==================\n",
    "\n",
    "def to_rfc3339(timestamp_str):\n",
    "\t# This function converts a timestamp to RFC3339 format\n",
    "\tdt = datetime.fromisoformat(timestamp_str)  # Parse input timestamp\n",
    "\treturn dt.strftime('%Y-%m-%dT%H:%M:%SZ')\t# Convert to RFC3339 format\n",
    "\n",
    "\n",
    "\n",
    "def get_previous_values(bucket, measurement, timestamp, num_values, org, url, token, username, password):\n",
    "\t\"\"\"\n",
    "\tThis function queries the last \"num_values\" of a single \"measurement\" before \"timestamp\" from \n",
    "\tInfluxDB multi-dimensional dataset in order to compute the correlation coefficient.\n",
    "\tIf values before the time stamp are less than \"num_values\" it gets all previous values.\n",
    "\n",
    "\tParameters:\n",
    "\t===========\n",
    "\t- bucket (str): \t\tInfluxDB bucket name.\n",
    "\t- measurement (str):\tThe variable name to extract.\n",
    "\t- timestamp (str): \t\tThe reference timestamp in RFC3339 format (e.g., \"2024-03-20T00:00:00Z\").\n",
    "\t- num_values (int): \tThe number of values (p) to extract.\n",
    "\t- org (str): \t\t\tInfluxDB organization name.\n",
    "\t- url (str): \t\t\tInfluxDB server URL.\n",
    "\t- token (str): \t\t\tAuthentication token.\n",
    "\t- username (str):\t\tAuthentication user name.\n",
    "\t- password (str):\t\tAuthentication password.\n",
    "\n",
    "\tReturns:\n",
    "\t- List of extracted values for the given variable.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tclient = InfluxDBClient(url=url, token=token, org=org, username=username, password=password)\n",
    "\tquery_api = client.query_api()\n",
    "\tformatted_timestamp = to_rfc3339(str(timestamp))\n",
    "\n",
    "\t# Construct the Flux query to extract one variable's values from a multi-dimensional dataset\n",
    "\tquery = f'''\n",
    "\tfrom(bucket: \"{bucket}\")\n",
    "\t  |> range(start:  time(v:\"2021-10-28T00:00:00Z\")) // the earliest timestamp\n",
    "\t  |> filter(fn: (r) => r[\"_field\"] == \"{measurement}\")\n",
    "\t  |> filter(fn: (r) => r[\"_time\"] <= time(v: \"{formatted_timestamp}\"))  // Before the timestamp\n",
    "\t  |> sort(columns: [\"_time\"], desc: true)\n",
    "\t  |> limit(n: {num_values})  // Extract up to num_values\n",
    "\t\t'''\n",
    "\n",
    "\t# Execute query\n",
    "\tresults = query_api.query(query=query, org=org)\n",
    "\n",
    "\t# Extract values\n",
    "\tvalues = [record.get_value() for table in results for record in table.records]\n",
    "\n",
    "\t#print(f\"Extracted values of '{measurement}' before {timestamp}:\")\n",
    "\treturn values\n",
    "\n",
    "\n",
    "def fetch_previous_values(var, timestamp, num_values):\n",
    "\t\"\"\"Fetches historical values for a given variable.\"\"\"\n",
    "\ttry:\n",
    "\t\treturn get_previous_values(\n",
    "\t\t\tbucket=bucket, measurement=var, timestamp=timestamp, num_values=num_values,\n",
    "\t\t\torg=org, url=influxdb_url, token=token, username=username, password=password\n",
    "\t\t)\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error fetching values for {var}: {e}\")\n",
    "\t\treturn []\n",
    "\n",
    "def fetch_events():\n",
    "\t\"\"\"Fetches time-series events from InfluxDB.\"\"\"\n",
    "\tquery = f'''\n",
    "\t\tfrom(bucket: \"{bucket}\")\n",
    "\t\t|> range(start: time(v: \"{start_time}\"))\n",
    "\t\t|> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "\t\t|> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "\t'''\n",
    "\ttry:\n",
    "\t\treturn list(query_api.query_stream(org=org, query=query))\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error querying InfluxDB: {e}\")\n",
    "\t\treturn []\n",
    "      \n",
    "def is_anomaly(T, variable_name, state):\n",
    "\t\"\"\"\n",
    "\tOptimized LDA-based anomaly detection function.\n",
    "\t\"\"\"\n",
    "\t# Extract state variables\n",
    "\tvariable_state = state[variable_name]\n",
    "\tbatch_events = variable_state[\"batch_events\"]\n",
    "\tnext_event = variable_state[\"next_event\"]\n",
    "\tM = variable_state[\"M\"]\n",
    "\tflag = variable_state[\"flag\"]\n",
    "\tactual_value = variable_state[\"actual_value\"]\n",
    "\tpredicted_value = variable_state[\"predicted_value\"]\n",
    "\tsliding_window_AARE = variable_state[\"sliding_window_AARE\"]\n",
    "\n",
    "\tif T < 2:\n",
    "\t\treturn False\n",
    "\n",
    "\t# Initialize LDA\n",
    "\tif 2 <= T < 5:\n",
    "\t\tif T == 2:\n",
    "\t\t\tM = train_model(list(batch_events))\n",
    "\t\telse:\n",
    "\t\t\tM = train_model(list(batch_events)[1:])\n",
    "\t\t\n",
    "\t\tvariable_state[\"M\"] = M\n",
    "\t\tpred_D_T_plus_1 = M.predict_next()\n",
    "\n",
    "\t\tactual_value.append(next_event)\n",
    "\t\tpredicted_value.append(pred_D_T_plus_1)\n",
    "\n",
    "\t\treturn False\n",
    "\n",
    "\telif 5 <= T < 7:\n",
    "\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\tsliding_window_AARE.append(AARE_T)\n",
    "\n",
    "\t\tM = train_model(list(batch_events)[1:])\n",
    "\t\tpred_D_T_plus_1 = M.predict_next()\n",
    "\n",
    "\t\tactual_value.append(next_event)\n",
    "\t\tpredicted_value.append(pred_D_T_plus_1)\n",
    "\n",
    "\t\tvariable_state[\"M\"] = M\n",
    "\t\treturn False\n",
    "\n",
    "\telif T >= 7:\n",
    "\t\tif flag:\n",
    "\t\t\tif T != 7:\n",
    "\t\t\t\tpred_D_T = M.predict_next()\n",
    "\t\t\t\tactual_value.append(batch_events[-1])\n",
    "\t\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\t\tsliding_window_AARE.append(AARE_T)\n",
    "\n",
    "\t\t\t# Calculate the threshold only once\n",
    "\t\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\t\tif AARE_T > Thd:\n",
    "\t\t\t\tmodel = train_model(list(batch_events)[0:-1])\n",
    "\t\t\t\tpred_D_T = model.predict_next()\n",
    "\n",
    "\t\t\t\tactual_value.append(batch_events[-1])\n",
    "\t\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\t\t\tsliding_window_AARE.append(AARE_T)\n",
    "\n",
    "\t\t\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\t\t\tif AARE_T > Thd:\n",
    "\t\t\t\t\tflag = False\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tvariable_state[\"M\"] = model\n",
    "\t\t\t\t\tflag = True\n",
    "\t\telse:\n",
    "\t\t\tmodel = train_model(list(batch_events)[0:-1])\n",
    "\t\t\tpred_D_T = model.predict_next()\n",
    "\t\t\tactual_value.append(batch_events[-1])\n",
    "\t\t\tpredicted_value.append(pred_D_T)\n",
    "\n",
    "\t\t\tAARE_T = calculate_aare(actual_value, predicted_value)\n",
    "\t\t\tsliding_window_AARE.append(AARE_T)\n",
    "\n",
    "\t\t\tThd = calculate_threshold(sliding_window_AARE)\n",
    "\n",
    "\t\t\tif AARE_T > Thd:\n",
    "\t\t\t\tflag = False\n",
    "\t\t\telse:\n",
    "\t\t\t\tvariable_state[\"M\"] = model\n",
    "\t\t\t\tflag = True\n",
    "\n",
    "\t\treturn not flag\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean Processing Time: 0.0511 sec, Std Dev: 0.4061 sec\n",
      "\n",
      "\n",
      "anomaly timestaps: \n",
      " {'2021-10-28T12:33:00Z', '2021-10-28T12:36:00Z', '2021-10-28T10:10:00Z', '2021-10-28T12:21:00Z', '2021-10-28T12:22:00Z', '2021-10-28T12:35:00Z', '2021-10-28T12:16:00Z', '2021-10-28T12:37:00Z', '2021-10-28T10:07:00Z', '2021-10-28T12:34:00Z', '2021-10-28T12:19:00Z', '2021-10-28T12:26:00Z', '2021-10-28T12:25:00Z', '2021-10-28T12:24:00Z', '2021-10-28T12:32:00Z', '2021-10-28T12:28:00Z', '2021-10-28T12:30:00Z', '2021-10-28T10:06:00Z', '2021-10-28T12:18:00Z', '2021-10-28T12:38:00Z', '2021-10-28T10:05:00Z', '2021-10-28T12:27:00Z', '2021-10-28T12:17:00Z', '2021-10-28T12:23:00Z', '2021-10-28T12:31:00Z', '2021-10-28T12:29:00Z', '2021-10-28T10:09:00Z', '2021-10-28T12:20:00Z', '2021-10-28T12:39:00Z', '2021-10-28T12:40:00Z', '2021-10-28T10:08:00Z'}\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n",
      "No sufficient events found.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(events) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     57\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo sufficient events found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \ttime\u001b[38;5;241m.\u001b[39msleep(poll_interval)\n\u001b[0;32m     59\u001b[0m \t\u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     61\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### RoLA Algorithm ###\n",
    "\t\t\n",
    "# Setting up the InfluxDB to consume data\n",
    "influxdb_url = \"http://localhost:8086\"\n",
    "token = \"random_token\"\n",
    "username = \"influx-admin\"\n",
    "password = \"ThisIsNotThePasswordYouAreLookingFor\"\n",
    "org = \"ORG\"\n",
    "bucket = \"system_state\"\n",
    "measurement = \"multivariate_dataset\"\n",
    "\n",
    "# Instantiate InfluxDB client\n",
    "client = InfluxDBClient(url=influxdb_url, token=token, org=org, username=username, password=password)\n",
    "write_api = client.write_api()\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Time Series Parameters\n",
    "T = 0\n",
    "p = 2880  # Number of previous values for correlation\n",
    "thd_pos, thd_neg = 0.95, -0.95\n",
    "poll_interval = 1  # Polling frequency in seconds\n",
    "time_increment = 1  # Time step increment\n",
    "start_time = \"2021-10-28T00:00:00Z\"\n",
    "\n",
    "# Variable Names\n",
    "variables = [\n",
    "\t\"SEB45Salinity\", \"SEB45Conductivity\", \"OptodeConcentration\", \"OptodeSaturation\",\n",
    "\t\"C3Temperature\", \"FlowTemperature\", \"OptodeTemperature\", \"C3Turbidity\", \"FlowFlow\"\n",
    "]\n",
    "\n",
    "# State Initialization\n",
    "state = {\n",
    "\tvar: {\n",
    "\t\t\"batch_events\": deque(maxlen=4),\n",
    "\t\t\"next_event\": deque(maxlen=1),\n",
    "\t\t\"actual_value\": deque([0] * 3, maxlen=3),\n",
    "\t\t\"predicted_value\": deque([0] * 3, maxlen=3),\n",
    "\t\t\"sliding_window_AARE\": deque(maxlen=8064),\n",
    "\t\t\"M\": None,\n",
    "\t\t\"flag\": True\n",
    "\t}\n",
    "\tfor var in variables\n",
    "}\n",
    "\n",
    "# List to store processing times\n",
    "processing_times = []\n",
    "anomaly_timestamps = []\n",
    "anomaly_variable_sets = []\n",
    "anomaly_datapoints_sets = []\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "\tevents = fetch_events()\n",
    "\tif len(events) < 3:\n",
    "\t\tprint(\"No sufficient events found.\")\n",
    "\t\ttime.sleep(poll_interval)\n",
    "\t\tcontinue\n",
    "\n",
    "\ttimestamp = 0\n",
    "\n",
    "\tfor i, event in enumerate(events):\n",
    "\t\titeration_start_time = time.time()  # Start time of this iteration\n",
    "\t\tanomalies = set()  # Reset anomalies for each data point\n",
    "\t\ttimestamp = event[\"_time\"]\n",
    "\n",
    "\t\t# Process each variable in the event\n",
    "\t\tfor var, value in event.values.items():\n",
    "\t\t\tif var in [\"result\", \"table\", \"_start\", \"_stop\", \"_time\", \"_measurement\", \"host\"]:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tstate[var][\"batch_events\"].append(value)\n",
    "\n",
    "\t\t\t# Set next event for early iterations (0 ≤ T < 7)\n",
    "\t\t\tif i < 7:\n",
    "\t\t\t\tstate[var][\"next_event\"] = events[i + 1][var]\n",
    "\n",
    "\t\t\t# Run anomaly detection\n",
    "\t\t\tif is_anomaly(T, var, state):\n",
    "\t\t\t\tanomalies.add(var)\n",
    "\n",
    "\t\t# Correlation & Polling Process\n",
    "\t\tif anomalies:\n",
    "\t\t\tcorrelated_vars = {a: fetch_previous_values(a, timestamp, p) for a in anomalies}\n",
    "\n",
    "\t\t\tfor a in anomalies:\n",
    "\t\t\t\tC_agree, C_disagree = 1, 0\n",
    "\t\t\t\tL_var, L_data = [a], [event[a]]\n",
    "\n",
    "\t\t\t\tfor b in variables:\n",
    "\t\t\t\t\tif b == a:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\ta_values = correlated_vars.get(a, [])\n",
    "\t\t\t\t\tb_values = fetch_previous_values(b, timestamp, p)\n",
    "\n",
    "\t\t\t\t\tif not a_values or not b_values:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tE_ab, _ = pearsonr(a_values, b_values)\n",
    "\t\t\t\t\texcept Exception:\n",
    "\t\t\t\t\t\tcontinue  # Handle potential computation errors\n",
    "\n",
    "\t\t\t\t\tif thd_neg <= E_ab <= thd_pos:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tif b in anomalies:\n",
    "\t\t\t\t\t\tC_agree += 1\n",
    "\t\t\t\t\t\tL_data.append(fetch_previous_values(b, timestamp, 1))\n",
    "\t\t\t\t\t\tL_var.append(b)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tC_disagree += 1\n",
    "\n",
    "\t\t\t\tif C_agree > C_disagree and (C_agree + C_disagree) > 1:\n",
    "\t\t\t\t\tanomaly_timestamps.append(timestamp)\n",
    "\t\t\t\t\t#anomaly_variable_sets.append(L_var)\n",
    "\t\t\t\t\t#anomaly_datapoints_sets.append(L_data)\n",
    "\t\t\t\t\t#print(f\"====> T: {T} ===>  {timestamp}\\nVariables: {L_var}\\nData: {L_data}\")\n",
    "\n",
    "\t\t# Increment T for the next data point\n",
    "\t\tT += 1\n",
    "\t\titeration_end_time = time.time()\n",
    "\n",
    "\t\t# Compute and store processing time\n",
    "\n",
    "\t\tprocessing_time = iteration_end_time - iteration_start_time\n",
    "\t\tprocessing_times.append(processing_time)\n",
    "\n",
    "\t\t#print(f\"Processed timestamp: {timestamp}, Processing time: {processing_time:.4f} seconds\")\n",
    "\n",
    "\t# Compute mean and standard deviation every 10 iterations\n",
    "\t#if len(processing_times) % 10 == 0:\n",
    "\tmean_time = np.mean(processing_times)\n",
    "\tstd_time = np.std(processing_times)\n",
    "\tprint(f\"\\n\\nMean Processing Time: {mean_time:.4f} sec, Std Dev: {std_time:.4f} sec\")\n",
    "\tprint(f\"\\n\\nanomaly timestaps: \\n {set(anomaly_timestamps)}\")\n",
    "\t\t\n",
    "\t# Update start time for the next iteration\n",
    "\tstart_time = (timestamp + timedelta(seconds=time_increment)).isoformat()\n",
    "\n",
    "\ttime.sleep(poll_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
